# Part 3: Generation & Prompting

How the LLM uses retrieved data.

| # | Question | File |
|---|----------|------|
| 10 | System prompt: no internal knowledge without context | [10-system-prompt-no-internal-knowledge-without-context.md](./10-system-prompt-no-internal-knowledge-without-context.md) |
| 11 | Return answer + source IDs and snippets (citations) | [11-return-answer-plus-source-ids-and-snippets.md](./11-return-answer-plus-source-ids-and-snippets.md) |
| 12 | Summarize retrieved docs before the generator | [12-summarize-retrieved-docs-before-generator.md](./12-summarize-retrieved-docs-before-generator.md) |
| 13 | Fallback when retriever returns low similarity | [13-fallback-when-retriever-returns-low-similarity.md](./13-fallback-when-retriever-returns-low-similarity.md) |
